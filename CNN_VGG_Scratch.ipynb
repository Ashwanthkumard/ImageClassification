{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://github.com/simongeek/KerasVGGcifar10/blob/master/vggkeras.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import timedelta\n",
    "from PIL import Image\n",
    "import sklearn\n",
    "\n",
    "from keras import callbacks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.initializers import glorot_normal\n",
    "from keras.utils import np_utils\n",
    "# from keras_sequential_ascii import sequential_model_to_ascii_printout\n",
    "# from keras import backend as K\n",
    "# if K.backend()=='tensorflow':\n",
    "#     K.set_image_dim_ordering(\"th\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as tfback\n",
    "\n",
    "def _get_available_gpus():\n",
    "    \"\"\"Get a list of available gpu devices (formatted as strings).\n",
    "\n",
    "    # Returns\n",
    "        A list of available GPU devices.\n",
    "    \"\"\"\n",
    "    #global _LOCAL_DEVICES\n",
    "    if tfback._LOCAL_DEVICES is None:\n",
    "        devices = tf.config.list_logical_devices()\n",
    "        tfback._LOCAL_DEVICES = [x.name for x in devices]\n",
    "    return [x for x in tfback._LOCAL_DEVICES if 'device:gpu' in x.lower()]\n",
    "\n",
    "tfback._get_available_gpus = _get_available_gpus\n",
    "tfback._get_available_gpus()\n",
    "tf.config.list_logical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "# session = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = 'images'\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(os.path.join(cwd,'train.csv'))\n",
    "test_csv = pd.read_csv(os.path.join(cwd,'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/Learnings/images/train/emergency'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(cwd,'images','train','emergency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(os.path.join(cwd,'Data','train','emergency')):\n",
    "    os.mkdir(os.path.join(cwd,'Data','train','emergency'))\n",
    "    os.mkdir(os.path.join(cwd,'Data','train','not_emergency'))\n",
    "#Move Images to class wise folders\n",
    "for ind,row in train_csv.iterrows():\n",
    "    if row['emergency_or_not']==0:\n",
    "        img = row['image_names']\n",
    "        shutil.copy(os.path.join(cwd,'images',img), os.path.join(cwd,'Data','train','not_emergency'))\n",
    "    else:\n",
    "        img = row['image_names']\n",
    "        shutil.copy(os.path.join(cwd,'images',img), os.path.join(cwd,'Data','train','emergency'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "#         brightness_range=[0.2,0,5],       \n",
    "        channel_shift_range=0.4,\n",
    "        cval=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1647 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_directory(\n",
    "    os.path.join(cwd,'Data','train'),\n",
    "    target_size=(224, 224),\n",
    "    batch_size=2,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= 2\n",
    "num_classes = 2\n",
    "epochs = 5\n",
    "BATCH_NORM = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', input_shape=(224,224,3), name='block1_conv1'))\n",
    "model.add(BatchNormalization()) if BATCH_NORM else None\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', name='block1_conv2'))\n",
    "model.add(BatchNormalization()) if BATCH_NORM else None\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool'))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', name='block2_conv1'))\n",
    "model.add(BatchNormalization()) if BATCH_NORM else None\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', name='block2_conv2'))\n",
    "model.add(BatchNormalization()) if BATCH_NORM else None\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool'))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same', name='block3_conv1'))\n",
    "model.add(BatchNormalization()) if BATCH_NORM else None\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same', name='block3_conv2'))\n",
    "model.add(BatchNormalization()) if BATCH_NORM else None\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same', name='block3_conv3'))\n",
    "model.add(BatchNormalization()) if BATCH_NORM else None\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same', name='block3_conv4'))\n",
    "model.add(BatchNormalization()) if BATCH_NORM else None\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool'))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same', name='block4_conv1'))\n",
    "model.add(BatchNormalization()) if BATCH_NORM else None\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same', name='block4_conv2'))\n",
    "model.add(BatchNormalization()) if BATCH_NORM else None\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same', name='block4_conv3'))\n",
    "model.add(BatchNormalization()) if BATCH_NORM else None\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same', name='block4_conv4'))\n",
    "model.add(BatchNormalization()) if BATCH_NORM else None\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool'))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same', name='block5_conv1'))\n",
    "model.add(BatchNormalization()) if BATCH_NORM else None\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same', name='block5_conv2'))\n",
    "model.add(BatchNormalization()) if BATCH_NORM else None\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same', name='block5_conv3'))\n",
    "model.add(BatchNormalization()) if BATCH_NORM else None\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same', name='block5_conv4'))\n",
    "model.add(BatchNormalization()) if BATCH_NORM else None\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1024))\n",
    "model.add(BatchNormalization()) if BATCH_NORM else None\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(4096, name='fc2'))\n",
    "model.add(BatchNormalization()) if BATCH_NORM else None\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(BatchNormalization()) if BATCH_NORM else None\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.0005, decay=0, nesterov=True)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Categorical_CrossEntropy')\n",
    "plt.title('Loss per epochs')\n",
    "plt.legend(['Train','Valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = []\n",
    "for im in tqdm(test_csv['image_names'].to_list()):\n",
    "    img = image.load_img(os.path.join(os.path.join(cwd,'images'),im))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255\n",
    "    test_image.append(img)\n",
    "test = np.array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict_classes(test)\n",
    "np.unique(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv['emergency_or_not'] = prediction\n",
    "test_csv.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu101.m47",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu101:m47"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
